{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning for NLP - Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RULES:\n",
    "\n",
    "* Do not create any additional cell\n",
    "\n",
    "* Fill in the blanks\n",
    "\n",
    "* All cells should be runnable (modulo trivial compatibility bugs that we'd fix)\n",
    "\n",
    "* 4 / 20 points will be allocated to the clarity of your code\n",
    "\n",
    "* Efficient code will have a bonus\n",
    "\n",
    "DELIVERABLE:\n",
    "\n",
    "* this notebook\n",
    "* the predictions of the SST test set\n",
    "\n",
    "DO NOT INCLUDE THE DATASETS IN THE DELIVERABLE.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_DATA = \"./data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Monolingual (English) word embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word2vec():\n",
    "    def __init__(self, fname, nmax=100000):\n",
    "        self.load_wordvec(fname, nmax)\n",
    "        self.word2id = dict.fromkeys(self.word2vec.keys())\n",
    "        self.id2word = {v: k for k, v in self.word2id.items()}\n",
    "        self.embeddings = np.array(self.word2vec.values())\n",
    "    \n",
    "    def load_wordvec(self, fname, nmax):\n",
    "        self.word2vec = {}\n",
    "        with io.open(fname, encoding='utf-8') as f:\n",
    "            next(f)\n",
    "            for i, line in enumerate(f):\n",
    "                word, vec = line.split(' ', 1)\n",
    "                self.word2vec[word] = np.fromstring(vec, sep=' ')\n",
    "                if i == (nmax - 1):\n",
    "                    break\n",
    "        print('Loaded %s pretrained word vectors' % (len(self.word2vec)))\n",
    "\n",
    "    def most_similar(self, w, K=5):\n",
    "        if w not in self.word2vec:\n",
    "            return []\n",
    "    \n",
    "        sim = [(k, self.score(w, k)) for k in self.word2vec.keys() if w!=k]\n",
    "        \n",
    "        return sorted(sim, key=itemgetter(1))[::-1][:K]\n",
    "    \n",
    "\n",
    "    def score(self, w1, w2):\n",
    "        if w1 not in self.word2vec or w2 not in self.word2vec:    #added after 'Berlin' returned error\n",
    "            return 0\n",
    "        \n",
    "        v1 = self.word2vec[w1] #w1 vector embedding\n",
    "        v2 = self.word2vec[w2] #w2 vector embedding\n",
    "        \n",
    "        return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 100000 pretrained word vectors\n",
      "cat dog 0.6716836662792491\n",
      "dog pet 0.6842064029669219\n",
      "dogs cats 0.7074389328052404\n",
      "paris france 0.7775108541288561\n",
      "germany berlin 0.7420295235998392\n",
      "[('cats', 0.8353184714264996), ('kitty', 0.8034410478493816), ('kitten', 0.8024762062392744), ('feline', 0.7680654076911861), ('kitties', 0.7237089223394709)]\n",
      "[('dogs', 0.855207916336258), ('puppy', 0.784569427961543), ('Dog', 0.7511571638004245), ('doggie', 0.7442413357176719), ('canine', 0.7421250622701409)]\n",
      "[('dog', 0.855207916336258), ('pooches', 0.7712664737679777), ('Dogs', 0.7704396457434113), ('doggies', 0.7699192773615036), ('canines', 0.7527040042648148)]\n",
      "[('france', 0.7775108541288561), ('Paris', 0.6845140397494099), ('london', 0.6728545431461278), ('berlin', 0.6424447628126261), ('tokyo', 0.6409621495653873)]\n",
      "[('austria', 0.7687671987529505), ('europe', 0.7597591231074469), ('german', 0.7445826305760618), ('berlin', 0.7420295235998392), ('poland', 0.7236705657279862)]\n"
     ]
    }
   ],
   "source": [
    "w2v = Word2vec(os.path.join(PATH_TO_DATA, 'crawl-300d-200k.vec'), nmax=100000)\n",
    "\n",
    "# You will be evaluated on the output of the following:\n",
    "for w1, w2 in zip(('cat', 'dog', 'dogs', 'paris', 'germany'), ('dog', 'pet', 'cats', 'france', 'berlin')):\n",
    "    print(w1, w2, w2v.score(w1, w2))\n",
    "for w1 in ['cat', 'dog', 'dogs', 'paris', 'germany']:\n",
    "    print(w2v.most_similar(w1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoV():\n",
    "    def __init__(self, w2v):\n",
    "        self.w2v = w2v\n",
    "    \n",
    "    def encode(self, sentences, idf=False):\n",
    "        # takes a list of sentences, outputs a numpy array of sentence embeddings\n",
    "        # see TP1 for help\n",
    "        sentemb = []\n",
    "        for sent in sentences:\n",
    "            words = sent.split(' ')\n",
    "            vec_list = []\n",
    "            \n",
    "            for i in range(len(words)):\n",
    "                \n",
    "                # Skip words without embeddings\n",
    "                if words[i] not in self.w2v.word2vec:\n",
    "                    continue\n",
    "                \n",
    "                # Get the right vector and idf-weight it or no\n",
    "                if words[i] in self.w2v.word2vec:\n",
    "                    vec = self.w2v.word2vec[words[i]]\n",
    "                    \n",
    "                if idf is False:\n",
    "                    # normal mean\n",
    "                    vec_list.append(vec)\n",
    "                \n",
    "                else:\n",
    "                    # idf-weighted mean\n",
    "                    idf_w = 1\n",
    "                    if words[i] in idf:\n",
    "                        idf_val = max(1, np.log10(len(sentences) / (idf[words[i]])))\n",
    "                    vec_list.append(vec * idf_w)\n",
    "                \n",
    "            # Take average of final word vectors\n",
    "            vec_sent = np.mean(np.array(vec_list), axis=0)\n",
    "            sentemb.append(vec_sent)\n",
    "                \n",
    "        return np.vstack(sentemb)\n",
    "\n",
    "    def most_similar(self, s, sentences, idf=False, K=5):\n",
    "        # get most similar sentences and **print** them\n",
    "        keys = self.encode(sentences, idf)\n",
    "        query = self.encode([s], idf)\n",
    "        \n",
    "        # Score/sentences\n",
    "        sent_score = np.array([self.vector_score(query[0], x) for x in keys])\n",
    "\n",
    "        # Sort the scores per descendin order\n",
    "        top_k = sent_score.argsort()[::-1][1:K+1]\n",
    "        \n",
    "        # Return k most similar\n",
    "        return [sentences[i] for i in top_k]\n",
    "\n",
    "    def score(self, s1, s2, idf=False):\n",
    "        S1_v = self.encode([s1], idf=idf)\n",
    "        S2_v = self.encode([s2], idf=idf)\n",
    "        \n",
    "        return self.vector_score(S1_v[0], S2_v[0])\n",
    "    \n",
    "    def vector_score(self, S1_v, S2_v):\n",
    "        return np.dot(S1_v, S2_v) / (np.linalg.norm(S1_v) * np.linalg.norm(S2_v))\n",
    "    \n",
    "    def build_idf(self, sentences):\n",
    "        # build the idf dictionary: associate each word to its idf value\n",
    "        idf = {}\n",
    "        for sent in sentences:\n",
    "            for w in set(sent):\n",
    "                idf[w] = idf.get(w, 0) + 1\n",
    "        return idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoV():\n",
    "    def __init__(self, w2v):\n",
    "        self.w2v = w2v\n",
    "    \n",
    "    def encode(self, sentences, idf=False):\n",
    "        # takes a list of sentences, outputs a numpy array of sentence embeddings\n",
    "        # see TP1 for help\n",
    "        sent_embed = []\n",
    "        for sent in sentences:\n",
    "            w = sent.split(' ')\n",
    "            w_vecs = []\n",
    "            for i in range(len(w)):\n",
    "                \n",
    "                if w[i] in self.w2v.word2vec:          \n",
    "                    # mean of word vectors\n",
    "                    w_vec = self.w2v.word2vec[w[i]]\n",
    "                if idf is False:\n",
    "                    w_vecs.append(w_vec)\n",
    "                    \n",
    "                # idf-weighted mean of word vectors    \n",
    "                else:\n",
    "                    val_idf = 1\n",
    "                    if w[i] in idf:\n",
    "                        val_idf = max(1, np.log10(len(sentences) / (idf[w[i]])))\n",
    "                    w_vecs.append(w_vec*val_idf)\n",
    "                \n",
    "            # Taking the mean of the word vectors in the senctences\n",
    "            sent_vec = np.mean(np.array(w_vecs), axis = 0)\n",
    "            sent_embed.append(sent_vec)\n",
    "            \n",
    "        return np.vstack(sent_embed)\n",
    "    \n",
    "    def most_similar(self, s, sentences, idf=False, K=5):\n",
    "        # get most similar sentences and **print** them\n",
    "        keys = self.encode(sentences, idf)\n",
    "        query = self.encode([s], idf)\n",
    "        \n",
    "        idf_score = np.array([self.score_vecs(query[0], x) for x in keys])\n",
    "        top_idx = idf_score.argsort()[::-1][:K]\n",
    "        print ([sentences[i] for i in top_idx])\n",
    "#         return [sentences[i] for i in top]\n",
    "        pass        \n",
    "    \n",
    "    def score(self, s1, s2, idf=False):\n",
    "        # cosine similarity: use   np.dot  and  np.linalg.norm\n",
    "        s1_vec = self.encode([s1], idf=idf)\n",
    "        s2_vec = self.encode([s2], idf=idf)\n",
    "        return self.score_vecs(s1_vec[0], s2_vec[0])\n",
    "    \n",
    "    def score_vecs(self, s1_vec, s2_vec):\n",
    "        return np.dot(s1_vec,s2_vec) / (np.linalg.norm(s1_vec) * np.linalg.norm(s2_vec))\n",
    " \n",
    "    def build_idf(self, sentences):\n",
    "        # build the idf dictionary: associate each word to its idf value\n",
    "        idf = {}\n",
    "        for sent in sentences:\n",
    "            for w in set(sent):\n",
    "                idf[w] = idf.get(w, 0) + 1\n",
    "        return idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 50000 pretrained word vectors\n",
      "['1 smiling african american boy .', 'an african american man smiling .', 'a little african american boy and girl looking up .', 'an african american man is sitting .', 'a girl in black hat holding an african american baby .']\n",
      "None\n",
      "0.551668865217505\n",
      "['1 smiling african american boy .', 'an african american man smiling .', 'a little african american boy and girl looking up .', 'an african american man is sitting .', 'a girl in black hat holding an african american baby .']\n",
      "None\n",
      "0.551668865217505\n"
     ]
    }
   ],
   "source": [
    "w2v = Word2vec(os.path.join(PATH_TO_DATA, 'crawl-300d-200k.vec'), nmax=50000)\n",
    "s2v = BoV(w2v)\n",
    "\n",
    "# Load sentences in \"PATH_TO_DATA/sentences.txt\"\n",
    "sentences = []\n",
    "with open(PATH_TO_DATA + '/sentences.txt') as f:\n",
    "    sentences = [s.strip() for s in f.readlines()]\n",
    "\n",
    "# Build idf scores for each word\n",
    "idf = s2v.build_idf(sentences)\n",
    "\n",
    "# You will be evaluated on the output of the following:\n",
    "print(s2v.most_similar('' if not sentences else sentences[10], sentences))  # BoV-mean\n",
    "print(s2v.score('' if not sentences else sentences[7], '' if not sentences else sentences[13]))\n",
    "\n",
    "print(s2v.most_similar('' if not sentences else sentences[10], sentences, idf))  # BoV-idf\n",
    "print(s2v.score('' if not sentences else sentences[7], '' if not sentences else sentences[13], idf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Multilingual (English-French) word embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider a bilingual dictionary of size V_a (e.g French-English).\n",
    "\n",
    "Let's define **X** and **Y** the **French** and **English** matrices.\n",
    "\n",
    "They contain the embeddings associated to the words in the bilingual dictionary.\n",
    "\n",
    "We want to find a **mapping W** that will project the source word space (e.g French) to the target word space (e.g English).\n",
    "\n",
    "Procrustes : **W\\* = argmin || W.X - Y ||  s.t  W^T.W = Id**\n",
    "has a closed form solution:\n",
    "**W = U.V^T  where  U.Sig.V^T = SVD(Y.X^T)**\n",
    "\n",
    "In what follows, you are asked to: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 10000 pretrained word vectors\n",
      "Loaded 10000 pretrained word vectors\n"
     ]
    }
   ],
   "source": [
    "# 1 - Download and load 50k first vectors of\n",
    "######## change to 10k vectors, my MacBook Air was crashing with 50k ###########\n",
    "\n",
    "#     https://s3-us-west-1.amazonaws.com/fasttext-vectors/wiki.en.vec\n",
    "#     https://s3-us-west-1.amazonaws.com/fasttext-vectors/wiki.fr.vec\n",
    "\n",
    "w2v_en = Word2vec(os.path.join(PATH_TO_DATA, 'wiki.en.vec'), nmax=10000)\n",
    "w2v_fr = Word2vec(os.path.join(PATH_TO_DATA, 'wiki.fr.vec'), nmax=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 - Get words that appear in both vocabs (= identical character strings)\n",
    "#     Use it to create the matrix X and Y (of aligned embeddings for these words)\n",
    "\n",
    "\n",
    "words_en = []\n",
    "words_fr = []\n",
    "words_map = []\n",
    "\n",
    "\n",
    "#EN tokens\n",
    "for word in w2v_en.word2id:\n",
    "    words_en.append(word)\n",
    "\n",
    "#FR tokens\n",
    "for word in w2v_fr.word2id:\n",
    "    words_fr.append(word)\n",
    "\n",
    "#Similar tokens\n",
    "for word in words_en:\n",
    "    if word in words_fr:\n",
    "        words_map.append(word)\n",
    "\n",
    "#Initialize matrices\n",
    "X = np.zeros((len(words_map), 300))\n",
    "Y = np.zeros((len(words_map), 300))\n",
    "\n",
    "#Matrix for French tokens\n",
    "for i in range(len(words_map)):\n",
    "    if words_map[i] in w2v_fr.word2id:\n",
    "        X[i] = w2v_fr.word2vec[words_map[i]]\n",
    "    else:\n",
    "        X[i] = np.zeros(300)\n",
    "\n",
    "#Matrix for English tokens\n",
    "for i in range(len(words_map)):\n",
    "    if words_map[i] in w2v_en.word2id:\n",
    "        Y[i] = w2v_en.word2vec[words_map[i]]\n",
    "    else:\n",
    "        Y[i] = np.zeros(300)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 - Get words that appear in both vocabs (= identical character strings)\n",
    "#     Use it to create the matrix X and Y (of aligned embeddings for these words)\n",
    "\n",
    "# TYPE CODE HERE\n",
    "# Getting the tokens - EN\n",
    "w_en = []\n",
    "for word in w2v_en.word2id:\n",
    "    w_en.append(word)\n",
    "\n",
    "# Getting the tokens - FR\n",
    "w_fr = []\n",
    "for word in w2v_fr.word2id:\n",
    "    w_fr.append(word)\n",
    "\n",
    "# Identical character strings\n",
    "w_sim = []\n",
    "for w in w_en:\n",
    "    if w in w_fr:\n",
    "        w_sim.append(w)\n",
    "\n",
    "# French matrix\n",
    "X = np.zeros((len(w_sim), 300))\n",
    "for i in range(len(w_sim)):\n",
    "    if w_sim[i] in w2v_fr.word2id:\n",
    "        X[i] = w2v_fr.word2vec[w_sim[i]]\n",
    "    else:\n",
    "        X[i] = np.zeros(300)\n",
    "\n",
    "# English matrix\n",
    "Y = np.zeros((len(w_sim), 300))\n",
    "for i in range(len(w_sim)):\n",
    "    if w_sim[i] in w2v_en.word2id:\n",
    "        Y[i] = w2v_en.word2vec[w_sim[i]]\n",
    "    else:\n",
    "        Y[i] = np.zeros(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 - Solve the Procrustes using the scipy package and: scipy.linalg.svd() and get the optimal W\n",
    "#     Now W*French_vector is in the same space as English_vector\n",
    "from scipy import linalg\n",
    "\n",
    "U, S, V_t = scipy.linalg.svd(np.matmul(Y, X.transpose()))\n",
    "W = np.matmul(U, V_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- French to English -----------------\n",
      "amour ['love', 'loving', 'loved', 'happiness', 'lovers']\n",
      "enfant ['child', 'infant', 'mother', 'parents', 'childhood']\n",
      "bleu ['blue', 'yellow', 'purple', 'red', 'orange']\n",
      "--------------- English to French -----------------\n",
      "love ['amour', 'aimer', 'amoureuse', 'amoureux', 'chante']\n",
      "children ['enfants', 'enfant', 'filles', 'parents', 's≈ìurs']\n",
      "blue ['blue', 'red', 'bleu', 'orange', 'black']\n"
     ]
    }
   ],
   "source": [
    "# 4 - After alignment with W, give examples of English nearest neighbors of some French words (and vice versa)\n",
    "#     You will be evaluated on that part and the code above\n",
    "\n",
    "Y_newspace = np.matmul(W, X)\n",
    "X_newspace = np.matmul(W.transpose(), Y)\n",
    "\n",
    "def fr_to_en(src_word, k=5):\n",
    "    \n",
    "    neighbors = {}\n",
    "    \n",
    "    if src_word in w2v_fr.word2vec:\n",
    "        for i in w2v_en.word2vec.keys():\n",
    "            tgt = np.matmul(Y, w2v_en.word2vec[i])\n",
    "            src = np.matmul(X_newspace, w2v_fr.word2vec[src_word])\n",
    "            neighbors[i] = np.dot(tgt, src)/(np.linalg.norm(tgt)*np.linalg.norm(src))\n",
    "\n",
    "    else:\n",
    "        return []\n",
    "    \n",
    "    k_nn = []\n",
    "    for i in range(k):\n",
    "        k_nn.append(max(neighbors, key=neighbors.get))\n",
    "        del neighbors[max(neighbors, key=neighbors.get)]\n",
    "        \n",
    "    return k_nn\n",
    "\n",
    "def en_to_fr(src_word, k=5):\n",
    "    neighbors = {}\n",
    "    \n",
    "    if src_word in w2v_en.word2vec:\n",
    "         for i in w2v_fr.word2vec.keys():\n",
    "            tgt = np.matmul(X, w2v_fr.word2vec[i])\n",
    "            src = np.matmul(Y_newspace, w2v_en.word2vec[src_word])\n",
    "            neighbors[i] = np.dot(tgt, src)/(np.linalg.norm(tgt)*np.linalg.norm(src))\n",
    "    else:\n",
    "        return []   \n",
    "    \n",
    "    k_nn = []\n",
    "    for i in range(k):\n",
    "        k_nn.append(max(neighbors, key=neighbors.get))\n",
    "        del neighbors[max(neighbors, key=neighbors.get)]\n",
    "        \n",
    "    return k_nn\n",
    "\n",
    "words_list_fr = ['amour', 'enfant', 'bleu']\n",
    "\n",
    "print('--------------- French to English -----------------')\n",
    "for mot in words_list_fr:\n",
    "    print (mot, fr_to_en(mot, 5))\n",
    "    \n",
    "words_list_en = ['love', 'children', 'blue']\n",
    "\n",
    "print('--------------- English to French -----------------')\n",
    "for word in words_list_en:\n",
    "    print (word, en_to_fr(word, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to dive deeper on this subject: https://github.com/facebookresearch/MUSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Sentence classification with BoV and scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 - Load train/dev/test of Stanford Sentiment TreeBank (SST)\n",
    "#     (https://nlp.stanford.edu/~socherr/EMNLP2013_RNTN.pdf)\n",
    "\n",
    "def load_data(file):\n",
    "    x = []\n",
    "    y = []\n",
    "    with open(PATH_TO_DATA + file) as f:\n",
    "        for l in f.readlines():\n",
    "            i, b = l.strip().split(' ', 1)\n",
    "            y.append(int(i))\n",
    "            x.append(b)\n",
    "    return x, y\n",
    "        \n",
    "        \n",
    "X_train_, y_train = load_data('SST/stsa.fine.train')\n",
    "X_dev_, y_dev = load_data('SST/stsa.fine.dev')\n",
    "\n",
    "\n",
    "X_test_ = []\n",
    "with open(PATH_TO_DATA + 'SST/stsa.fine.test.X') as f:\n",
    "    for l in f.readlines():\n",
    "        i, b = l.strip().split(' ', 1)\n",
    "        X_test_.append(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 50000 pretrained word vectors\n"
     ]
    }
   ],
   "source": [
    "# 2 - Encode sentences with the BoV model above\n",
    "w2v = Word2vec(os.path.join(PATH_TO_DATA, 'crawl-300d-200k.vec'), nmax=50000)\n",
    "s2v = BoV(w2v)\n",
    "\n",
    "X_train = s2v.encode(X_train_, idf=False)\n",
    "X_dev = s2v.encode(X_dev_, idf=False)\n",
    "X_test = s2v.encode(X_test_, idf=False)\n",
    "\n",
    "X_train_idf = s2v.encode(X_train_, idf=idf)\n",
    "X_dev_idf = s2v.encode(X_dev_, idf=idf)\n",
    "X_test_idf = s2v.encode(X_test_, idf=idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4259763851044505\n",
      "Final accuracy: 0.4296094459582198\n",
      "Accuracy idf: 0.4250681198910082\n",
      "Final accuracy with idf: 0.4250681198910082\n"
     ]
    }
   ],
   "source": [
    "# 3 - Learn Logistic Regression on top of sentence embeddings using scikit-learn\n",
    "#     (consider tuning the L2 regularization on the dev set)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, mean_squared_error\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "############################### WITHOUT IDF ######################################\n",
    "# Instantiate a logistic regression classifier    \n",
    "lg = LogisticRegression()\n",
    "lg.fit(X_train, y_train)\n",
    "print('Accuracy: ' + str(lg.score(X_dev, y_dev)))\n",
    "\n",
    "\n",
    "# Setup the hyperparameter grid\n",
    "c_space = np.logspace(-5, 8, 15)\n",
    "param_grid = {'C': c_space}\n",
    "\n",
    "# Instantiate the GridSearchCV object:\n",
    "lg_cv = GridSearchCV(lg, param_grid, cv=5)\n",
    "lg_cv.fit(X_train, y_train)\n",
    "\n",
    "#best parameters and score after hyperparameter tuning:\n",
    "#best_params : 'C': 0.4393970560760795\n",
    "#best_score : 0.4330524344569288\n",
    "\n",
    "lg_tuned = LogisticRegression(penalty = 'l2', C = 0.4393970560760795)\n",
    "lg_tuned.fit(X_train, y_train)\n",
    "\n",
    "#Measure accuracy\n",
    "score = lg_tuned.score(X_dev, y_dev)\n",
    "print(\"Final accuracy: \" + format(score))\n",
    "\n",
    "############################### WITH IDF ######################################\n",
    "\n",
    "# Instantiate a logistic regression classifier\n",
    "lg_idf = LogisticRegression()\n",
    "lg_idf.fit(X_train_idf, y_train)\n",
    "print('Accuracy idf: ' + str(lg_idf.score(X_dev_idf, y_dev)))\n",
    "\n",
    "\n",
    "# Setup the hyperparameter grid\n",
    "c_space = np.logspace(-5, 8, 15)\n",
    "param_grid = {'C': c_space}\n",
    "\n",
    "# Instantiate the GridSearchCV object:\n",
    "lg_cv_idf = GridSearchCV(lg_idf, param_grid, cv=5)\n",
    "lg_cv_idf.fit(X_train_idf, y_train)\n",
    "\n",
    "#best parameters and score after hyperparameter tuning:\n",
    "#best_params : 'C': 0.4393970560760795\n",
    "#best_score : 0.4330524344569288\n",
    "\n",
    "lg_tuned_idf = LogisticRegression(penalty = 'l2', C = 0.4393970560760795)\n",
    "lg_tuned_idf.fit(X_train_idf, y_train)\n",
    "\n",
    "#Measure accuracy\n",
    "score_idf = lg_tuned_idf.score(X_dev_idf, y_dev)\n",
    "print(\"Final accuracy with idf: \" + format(score_idf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 - Produce 2210 predictions for the test set (in the same order). One line = one prediction (=0,1,2,3,4).\n",
    "#     Attach the output file \"logreg_bov_y_test_sst.txt\" to your deliverable.\n",
    "#     You will be evaluated on the results of the test set.\n",
    "\n",
    "#Prediction for test set\n",
    "y_pred_test = lg_tuned.predict(X_test)\n",
    "\n",
    "def generate_pred(file):\n",
    "    f=open(file, 'w')  \n",
    "    \n",
    "#iterate over the 2210 lines of y_pred_test\n",
    "    for i in range(2210):\n",
    "        f.write(str(y_pred_test[i]))                   \n",
    "    f.close()\n",
    "    \n",
    "generate_pred('logreg_bov_y_test_sst.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA: 0.416894\n",
      "KNN: 0.318801\n",
      "CART: 0.258856\n",
      "NB: 0.383288\n",
      "SVM: 0.270663\n"
     ]
    }
   ],
   "source": [
    "# BONUS!\n",
    "# 5 - Try to improve performance with another classifier\n",
    "#     Attach the output file \"XXX_bov_y_test_sst.txt\" to your deliverable (where XXX = the name of the classifier)\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "models = []\n",
    "\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC()))\n",
    "\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "scoring = 'accuracy'\n",
    "\n",
    "for name, model in models:\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    #Measure accuracy\n",
    "    score = model.score(X_dev, y_dev)\n",
    "    \n",
    "    results.append(score)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f\" % (name, score)\n",
    "    print(msg)\n",
    "    \n",
    "    \n",
    "    \n",
    "#generate_pred('SVM_bov_y_test_sst.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Sentence classification with LSTMs in Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 - Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "import np_utils\n",
    "from keras.utils import np_utils\n",
    "import keras\n",
    "from keras.preprocessing.text import one_hot, text_to_word_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 - Load train/dev/test sets of SST\n",
    "PATH_TO_DATA = \"./data/\"\n",
    "\n",
    "def load_data(file):\n",
    "    x = []\n",
    "    y = []\n",
    "    with open(PATH_TO_DATA + file) as f:\n",
    "        for l in f.readlines():\n",
    "            i, b = l.strip().split(' ', 1)\n",
    "            y.append(int(i))\n",
    "            x.append(b)\n",
    "    return x, y\n",
    "        \n",
    "        \n",
    "X_train, y_train = load_data('SST/stsa.fine.train')\n",
    "X_dev, y_dev = load_data('SST/stsa.fine.dev')\n",
    "\n",
    "\n",
    "X_test = []\n",
    "with open(PATH_TO_DATA + 'SST/stsa.fine.test.X') as f:\n",
    "    for l in f.readlines():\n",
    "        i, b = l.strip().split(' ', 1)\n",
    "        X_test.append(b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size :184837\n"
     ]
    }
   ],
   "source": [
    "# 2 - Transform text to integers using keras.preprocessing.text.one_hot function\n",
    "#     https://keras.io/preprocessing/text/\n",
    "\n",
    "vocab=[]\n",
    "for sent in X_train:\n",
    "    for word in sent.split(' '):\n",
    "        vocab.append(word)\n",
    "for sent in X_dev:\n",
    "    for word in sent.split(' '):\n",
    "        vocab.append(word)\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "print('Vocab size :' + str(vocab_size))\n",
    "\n",
    "dev_int = [one_hot(i, vocab_size) for i in X_dev]\n",
    "test_int = [one_hot(i, vocab_size) for i in X_test]\n",
    "train_int = [one_hot(i, vocab_size) for i in X_train]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Padding input data**\n",
    "\n",
    "Models in Keras (and elsewhere) take batches of sentences of the same length as input. It is because Deep Learning framework have been designed to handle well Tensors, which are particularly suited for fast computation on the GPU.\n",
    "\n",
    "Since sentences have different sizes, we \"pad\" them. That is, we add dummy \"padding\" tokens so that they all have the same length.\n",
    "\n",
    "The input to a Keras model thus has this size : (batchsize, maxseqlen) where maxseqlen is the maximum length of a sentence in the batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 - Pad your sequences using keras.preprocessing.sequence.pad_sequences\n",
    "#     https://keras.io/preprocessing/sequence/\n",
    "\n",
    "\n",
    "#[max(len(x) for x in test_int)]) #51\n",
    "#[max(len(x) for x in train_int)]) #49\n",
    "#[max(len(x) for x in dev_int)]) #44\n",
    "\n",
    "#Padding with max_len of all 3 datasets\n",
    "dev_pad = keras.preprocessing.sequence.pad_sequences(dev_int, maxlen=51)\n",
    "test_pad = keras.preprocessing.sequence.pad_sequences(test_int, maxlen=51)\n",
    "train_pad = keras.preprocessing.sequence.pad_sequences(train_int, maxlen=51)\n",
    "\n",
    "#Convert labels to categorical\n",
    "X_train = np.array(train_pad)\n",
    "y_train = np_utils.to_categorical(y_train, num_classes=5)\n",
    "\n",
    "X_dev=np.array(dev_pad)\n",
    "y_dev=np_utils.to_categorical(y_dev, num_classes=5)\n",
    "\n",
    "X_test=np.array(test_pad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 - Design and train your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/noemiequere/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:21: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(64, dropout=0.2, recurrent_dropout=0.2)`\n"
     ]
    }
   ],
   "source": [
    "# 4 - Design your encoder + classifier using keras.layers\n",
    "#     In Keras, Torch and other deep learning framework, we create a \"container\" which is the Sequential() module.\n",
    "#     Then we add components to this contained : the lookuptable, the LSTM, the classifier etc.\n",
    "#     All of these components are contained in the Sequential() and are trained together.\n",
    "\n",
    "\n",
    "# ADAPT CODE BELOW\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, Activation\n",
    "\n",
    "embed_dim  = 48  # word embedding dimension\n",
    "nhid       = 64  # number of hidden units in the LSTM\n",
    "vocab_size = vocab_size  # size of the vocabulary\n",
    "n_classes  = 5\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embed_dim))\n",
    "model.add(LSTM(nhid, dropout_W=0.2, dropout_U=0.2))\n",
    "model.add(Dense(n_classes, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, None, 48)          8872176   \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 64)                28928     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 8,901,429\n",
      "Trainable params: 8,901,429\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 5 - Define your loss/optimizer/metrics\n",
    "\n",
    "# MODIFY CODE BELOW\n",
    "\n",
    "loss_classif     =  'binary_crossentropy' # find the right loss for multi-class classification\n",
    "optimizer        =  'adam' # find the right optimizer\n",
    "metrics_classif  =  ['accuracy']\n",
    "\n",
    "# Observe how easy (but blackboxed) this is in Keras\n",
    "model.compile(loss=loss_classif,\n",
    "              optimizer=optimizer,\n",
    "              metrics=metrics_classif)\n",
    "print(model.summary())\n",
    "    #return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8544 samples, validate on 1101 samples\n",
      "Epoch 1/8\n",
      "8544/8544 [==============================] - 70s 8ms/step - loss: 0.5025 - acc: 0.7975 - val_loss: 0.4900 - val_acc: 0.8000\n",
      "Epoch 2/8\n",
      "8544/8544 [==============================] - 60s 7ms/step - loss: 0.4597 - acc: 0.7998 - val_loss: 0.4519 - val_acc: 0.7922\n",
      "Epoch 3/8\n",
      "8544/8544 [==============================] - 59s 7ms/step - loss: 0.3743 - acc: 0.8245 - val_loss: 0.4639 - val_acc: 0.7864\n",
      "Epoch 4/8\n",
      "8544/8544 [==============================] - 62s 7ms/step - loss: 0.2833 - acc: 0.8800 - val_loss: 0.5143 - val_acc: 0.7777\n",
      "Epoch 5/8\n",
      "8544/8544 [==============================] - 63s 7ms/step - loss: 0.2003 - acc: 0.9236 - val_loss: 0.5857 - val_acc: 0.7718\n",
      "Epoch 6/8\n",
      "8544/8544 [==============================] - 62s 7ms/step - loss: 0.1439 - acc: 0.9482 - val_loss: 0.6562 - val_acc: 0.7600\n",
      "Epoch 7/8\n",
      "8544/8544 [==============================] - 62s 7ms/step - loss: 0.1094 - acc: 0.9619 - val_loss: 0.7466 - val_acc: 0.7515\n",
      "Epoch 8/8\n",
      "8544/8544 [==============================] - 59s 7ms/step - loss: 0.0865 - acc: 0.9713 - val_loss: 0.8239 - val_acc: 0.7540\n",
      "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x14ceed438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x138c39160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 6 - Train your model and find the best hyperparameters for your dev set\n",
    "#     you will be evaluated on the quality of your predictions on the test set\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn import grid_search\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "##After several trials, I had the best results with batch_size = 30 and n_epochs = 8\n",
    "\n",
    "bs = 30\n",
    "n_epochs = 8\n",
    "\n",
    "history = model.fit(X_train, y_train, batch_size=bs, epochs=n_epochs, validation_data=(X_dev, y_dev))\n",
    "\n",
    "model.metrics_names\n",
    "print(history.history.keys())\n",
    "#  \"Accuracy\"\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "# \"Loss\"\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7 - Generate your predictions on the test set using model.predict(x_test)\n",
    "#     https://keras.io/models/model/\n",
    "#     Log your predictions in a file (one line = one integer: 0,1,2,3,4)\n",
    "#     Attach the output file \"logreg_lstm_y_test_sst.txt\" to your deliverable.\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "y_pred_final=[]\n",
    "for i in range(y_pred.shape[0]):\n",
    "    y_pred_final.append(np.argmax(y_pred[i]))\n",
    "\n",
    "f = open('logreg_lstm_y_test_sst.txt', 'w')\n",
    "    \n",
    "for i in range(len(y_pred_final)):                  \n",
    "    f.write(str(y_pred_final[i]))                  \n",
    "f.close()  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 -- innovate !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_12 (Embedding)     (None, None, 48)          8872176   \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, None, 32)          4640      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, None, 32)          0         \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 64)                24832     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 8,901,973\n",
      "Trainable params: 8,901,973\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 8544 samples, validate on 1101 samples\n",
      "Epoch 1/12\n",
      "8544/8544 [==============================] - 49s 6ms/step - loss: 1.5435 - acc: 0.3052 - val_loss: 1.4061 - val_acc: 0.3742\n",
      "Epoch 2/12\n",
      "8544/8544 [==============================] - 47s 5ms/step - loss: 1.2019 - acc: 0.4826 - val_loss: 1.3512 - val_acc: 0.3806\n",
      "Epoch 3/12\n",
      "8544/8544 [==============================] - 44s 5ms/step - loss: 0.7871 - acc: 0.6809 - val_loss: 1.6686 - val_acc: 0.3878\n",
      "Epoch 4/12\n",
      "8544/8544 [==============================] - 42s 5ms/step - loss: 0.4353 - acc: 0.8426 - val_loss: 2.0929 - val_acc: 0.3497\n",
      "Epoch 5/12\n",
      "8544/8544 [==============================] - 46s 5ms/step - loss: 0.2235 - acc: 0.9237 - val_loss: 2.5447 - val_acc: 0.3706\n",
      "Epoch 6/12\n",
      "8544/8544 [==============================] - 46s 5ms/step - loss: 0.1203 - acc: 0.9615 - val_loss: 2.9631 - val_acc: 0.3697\n",
      "Epoch 7/12\n",
      "8544/8544 [==============================] - 48s 6ms/step - loss: 0.0730 - acc: 0.9785 - val_loss: 3.4421 - val_acc: 0.3542\n",
      "Epoch 8/12\n",
      "8544/8544 [==============================] - 49s 6ms/step - loss: 0.0509 - acc: 0.9860 - val_loss: 3.6099 - val_acc: 0.3642\n",
      "Epoch 9/12\n",
      "8544/8544 [==============================] - 48s 6ms/step - loss: 0.0341 - acc: 0.9902 - val_loss: 3.7228 - val_acc: 0.3678\n",
      "Epoch 10/12\n",
      "8544/8544 [==============================] - 49s 6ms/step - loss: 0.0240 - acc: 0.9940 - val_loss: 4.0897 - val_acc: 0.3688\n",
      "Epoch 11/12\n",
      "8544/8544 [==============================] - 43s 5ms/step - loss: 0.0179 - acc: 0.9953 - val_loss: 4.4024 - val_acc: 0.3533\n",
      "Epoch 12/12\n",
      "8544/8544 [==============================] - 45s 5ms/step - loss: 0.0202 - acc: 0.9945 - val_loss: 4.2048 - val_acc: 0.3388\n",
      "2210/2210 [==============================] - 1s 254us/step\n"
     ]
    }
   ],
   "source": [
    "# 8 - Open question: find a model that is better on your dev set\n",
    "#     (e.g: use a 1D ConvNet, use a better classifier, pretrain your lookup tables ..)\n",
    "#     you will get point if the results on the test set are better: be careful of not overfitting your dev set too much..\n",
    "#     Attach the output file \"XXX_XXX_y_test_sst.txt\" to your deliverable.\n",
    "\n",
    "from keras.layers import Conv1D, Dropout, MaxPooling1D, Flatten\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "#Building a new linear classifier\n",
    "model_2 = Sequential()\n",
    "\n",
    "#Adding Conv1D layer\n",
    "model_2.add(Embedding(vocab_size, embed_dim))\n",
    "model_2.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "model_2.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "#Adding LSTM layer\n",
    "model_2.add(LSTM(nhid))\n",
    "model_2.add(Dense(n_classes, activation='softmax'))\n",
    "\n",
    "#Compile the model\n",
    "\n",
    "\n",
    "model_2.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics=['accuracy'])\n",
    "model_2.summary()\n",
    "            \n",
    "model_2.fit(X_train, y_train, validation_data=(X_dev, y_dev), epochs=12)\n",
    "\n",
    "model_2.evaluate(X_test, y_test)\n",
    "            \n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "y_pred_final=[]\n",
    "for i in range(y_pred.shape[0]):\n",
    "    y_pred_final.append(np.argmax(y_pred[i]))\n",
    "\n",
    "f = open('1DConv_lstm_y_test_sst.txt', 'w')\n",
    "    \n",
    "for i in range(len(y_pred_final)):                  \n",
    "    f.write(str(y_pred_final[i]))                  \n",
    "f.close() \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
